{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize LibriTTS-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/projects/ai/audio/illu/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modeling.utils import PromptEncoder\n",
    "\n",
    "prompt_encoder = PromptEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, concatenate_datasets, DatasetDict\n",
    "\n",
    "ds = load_from_disk(\"../datasets/encoded_libritts\")\n",
    "ds = DatasetDict({\n",
    "    'train': concatenate_datasets([ds['train.clean.100'], ds['train.clean.360']]),\n",
    "    'test': ds['test.clean'],\n",
    "    'dev': ds['dev.clean']\n",
    "})\n",
    "ds = ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_normalized': 'The weapon must still have been there.',\n",
       " 'text_original': 'The weapon must still have been there.',\n",
       " 'speaker_id': '3081',\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/5551a515e85b9e463062524539c2e1cb52ba32affe128dffd866db0205248bdd/LibriTTS_R/dev-clean/3081/166546/3081_166546_000101_000001.wav',\n",
       " 'chapter_id': '166546',\n",
       " 'id': '3081_166546_000101_000001',\n",
       " 'codes': tensor([[1049, 1114, 1609,  784,  499,  260, 1011,    8, 1407,  540, 1615,  561,\n",
       "          1945,  201, 1324,  668,  376, 1849,    9, 1921, 1921, 1683,  228,  897,\n",
       "          1677,  518],\n",
       "         [ 811, 1149,  739,  410, 1367, 1305, 2046, 1287,  886, 1995, 1727,  678,\n",
       "          1455,  352, 1914, 1504, 1138, 1154,  669, 1217, 1450, 1003, 1711,  488,\n",
       "           342,  844],\n",
       "         [ 373, 1464, 2013, 1306,  102,  561,  852,  267,  442,  718, 1501, 1455,\n",
       "           233, 1015,  963,   29,  496, 1728,  783, 1870,  879, 1802, 1523,  231,\n",
       "           333,  199],\n",
       "         [ 131, 1957,   58,  500, 1489, 1451, 1946, 1800,   68,   46,  214, 2008,\n",
       "           539,  217,  403, 1270,  112, 1922,  104,  962, 1194, 1785,   36,  603,\n",
       "           212,  104],\n",
       "         [  68,  674, 1446, 1356,  457,   49,  541,  505,  122,  457, 1773,   44,\n",
       "           823, 1423, 1693,  644,  297,  272,  720,   91,  635, 1187,   64,  485,\n",
       "           844,  417],\n",
       "         [1739,  954,  935,  640, 1509,   63,  398, 1824,  707, 1948, 1273, 1832,\n",
       "           553, 1245,  110, 1521, 1865, 1554,  317, 1349,  853, 1955,  693,  648,\n",
       "          1760,   38],\n",
       "         [1238, 1560, 1151, 1486, 1575, 1451, 1491, 1389, 1967,  277, 1175, 1285,\n",
       "          1240,  467, 1202, 1507,  848,  358,  428, 1667, 1888, 1039,   75, 1364,\n",
       "          1412, 1242],\n",
       "         [ 754, 1956,   28, 1921, 1079,  729,  414, 1887, 1508,  585, 1804, 1803,\n",
       "           156,  927,  407,  406,  396, 1978, 1321, 1880,  298, 1300, 1513, 1213,\n",
       "           275, 1477],\n",
       "         [1323,  496, 1088, 1314,  882, 1226, 1121,  541, 1829, 1897, 1288, 2037,\n",
       "           259,  821, 1980,  268,  882, 1041, 1643,  738, 1043, 1949,  631,  508,\n",
       "            53, 1106],\n",
       "         [ 278,  857, 1272, 1645,   10,  925, 1577, 1713,  827,  440,  569, 2028,\n",
       "           913,  913, 1422,  793,  151, 1053, 1032, 1165, 1935, 1406, 1238,    6,\n",
       "          1527,  337],\n",
       "         [ 415,  563,   83,  254,  233,  168,  348,  667, 1609,  738, 1188,  146,\n",
       "          1550,  320, 1955, 1559,   99,  814, 1048,  600,  237,  446, 1304, 1580,\n",
       "           504, 1325],\n",
       "         [ 326,  116, 1240,  139,  667, 1591, 1684,  483, 1223, 2008,  386,  393,\n",
       "           240,  766,  330, 1838, 1644,  712, 1107, 1147, 1693,  485, 2021,  426,\n",
       "           282,  181],\n",
       "         [1912,  257, 1163,  639, 1066, 1679, 1581, 1253, 1177, 1363,  109, 1527,\n",
       "          2040,  633, 1026,  626,  825,  922, 1101, 1107,  709,  814,  780,  782,\n",
       "          1268,  671],\n",
       "         [1924, 1701, 1601, 1515, 1479, 1130, 1240, 1665, 1129, 1091,  838, 1358,\n",
       "          1358, 1930, 1692, 1596,  304, 1264, 1791,  460, 1729, 1840, 1557, 1088,\n",
       "           561,  811],\n",
       "         [ 942, 1182,  308,  463,  369,  314, 1654, 1144,  309, 1046, 1702,  810,\n",
       "           130,  130,  613, 1532,  833,  305,  853,  454, 1569,  992, 1662,  160,\n",
       "           901,  757],\n",
       "         [1942,  158, 1831,  759,  797, 1058,  136, 1588, 1883, 1126,  784, 1255,\n",
       "           213,  893, 1526, 1016,  132,  603, 1738,  597,  649,  726,  698, 1477,\n",
       "           508, 1738],\n",
       "         [ 491,   36, 1776,  422,  491, 1569, 1478, 1295, 1494, 1093,  491,  210,\n",
       "           156,   79, 1692,   78,  875, 1723,  445, 1342,  556,  186, 1758,   71,\n",
       "          1423, 1353],\n",
       "         [1642, 1812,  321,  638,  582, 1995, 1114,   28, 1733,   98,  734,   20,\n",
       "          1219,  168,  303, 1110,  608, 1070,  852, 1204, 1422,  843, 1595, 1685,\n",
       "          1352, 1874],\n",
       "         [ 699,  845, 1430,  859, 1787, 1697, 1277, 1817, 1598, 1886,  752,  805,\n",
       "           715,  445,  615, 1356,  537, 2044,  289, 1069, 1670, 1477, 1601, 1297,\n",
       "            52, 1758],\n",
       "         [1853,  789,   22,  311, 1347, 1950,  625, 1637, 1299,  968, 1386, 1654,\n",
       "          1051, 1172,  683, 1179,  790, 1419, 1397, 1549, 1943, 1432, 1421,  895,\n",
       "           321,  725],\n",
       "         [1003, 1196,  154,  772, 1166, 1813,   24,  769,  666,  977, 1504, 1411,\n",
       "           463, 1612, 1718, 1939, 1306, 1523, 1780,  987,  823, 1166, 1368,  453,\n",
       "          1923, 1856],\n",
       "         [ 531,  503, 1790, 1952,  595,  906,  469,  787,  267,  306,  614, 1621,\n",
       "          1739,  712,   55, 1655,  133,   77,  219, 1058, 1466, 1734, 1631, 1947,\n",
       "            69,  172],\n",
       "         [ 466,   41,  559, 1156, 1180,  640,  445,  638, 1818,  444, 1211, 1749,\n",
       "           547,  933, 1676,  827,  814, 1740,  116,  537,  242,  348, 1575, 1633,\n",
       "           452, 1612],\n",
       "         [ 709, 1187, 1204, 1311, 1614,  686,  137,  166, 1961, 1335,  952, 1238,\n",
       "           582,  601,  406, 1247,  228,  873, 1774, 2016,  229, 1805, 1310,  726,\n",
       "           300,   74],\n",
       "         [ 204, 1698, 2023, 1787,  354,   74, 1647,  931,  148,  221, 1730, 1252,\n",
       "          1586,  700,  610, 1646, 2040, 1475,  612, 1959, 1121, 1651,  586, 1468,\n",
       "          1376,  810],\n",
       "         [1704,  287, 1734,  424, 1792, 2024,  375,  266, 1675,  530, 1619,  420,\n",
       "           459, 1353, 1810,  228, 1152, 1858, 2002,  373,  898,  282, 1813, 1408,\n",
       "          1272,  645],\n",
       "         [1778,  776,  351,  560,  545,  572,  405, 1805,  195,   75,  260, 1909,\n",
       "           423, 1232,  141, 1581,  746,  233, 1272, 1470,  648,  628,  356, 1686,\n",
       "          1305, 1323],\n",
       "         [1388, 1141,  807, 1235, 1033,  376, 1559, 1803,  711,  966,  523,  710,\n",
       "          1060,  829, 1046,  306, 1940, 1050, 1254,  829,  184,  505,   53,  108,\n",
       "          1647, 1934],\n",
       "         [ 769,   61,  172, 1704,  754, 1521, 1963,  906, 1400, 1965,  670,  144,\n",
       "          1858, 1692,  195, 1111, 1210,  257,  389, 1920, 1397, 1020, 1003, 1286,\n",
       "          1756, 1938],\n",
       "         [1171,  398, 1592, 1209,  485,  279, 1253,  249,  710, 1275,  684,  435,\n",
       "          1058, 1243, 1265, 1189,  518, 1970, 1864, 1484, 1727,  892,  477, 1845,\n",
       "          1585,   61],\n",
       "         [  17,  573, 1576, 1821,  656,  330,  167,  136, 1765,   49,  335,  273,\n",
       "           337, 1136,   79, 1052, 1443,  807,  905, 1989, 1777,  688,   49, 1201,\n",
       "          1871,  183],\n",
       "         [1607, 1250,  529, 1603,  548, 1361,  471, 1583, 1938,  406,  766, 1897,\n",
       "           607,  337, 1540, 1999, 1582,  698,  722, 1677,  820, 1669, 1983,  780,\n",
       "           807, 1974]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['dev'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/projects/ai/audio/illu/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    }
   ],
   "source": [
    "from transformers import MimiModel\n",
    "\n",
    "mimi_model = MimiModel.from_pretrained('kyutai/mimi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prove that restoring the residual restores the codes (or close to it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'codes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mprint\u001b[39m(codes[:, start_depth:, \u001b[32m2\u001b[39m])\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mprint\u001b[39m(out_indices[:, :, \u001b[32m2\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m get_residual(\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcodes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mKeyError\u001b[39m: 'codes'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Deliberately break the model for testing purposes\n",
    "mimi_model.quantizer.acoustic_residual_vector_quantizer.output_proj = None\n",
    "\n",
    "def get_residual(codes: torch.Tensor, start_depth=16):\n",
    "    if codes.ndim == 2:\n",
    "        codes = codes.unsqueeze(0)\n",
    "    print(codes.shape)\n",
    "\n",
    "    # Full residual sum before out_proj\n",
    "    acoustic_sum = mimi_model.quantizer.acoustic_residual_vector_quantizer.decode(codes[:, 1:, :])\n",
    "    # Sum of first 15 acoustic codes (aka the remaining decoder)\n",
    "    acoustic_autoreg_sum = mimi_model.quantizer.acoustic_residual_vector_quantizer.decode(codes[:, 1:start_depth, :])\n",
    "\n",
    "\n",
    "    # Remaining sum (aka what we'll have to predict)\n",
    "    acoustic_predicted_residual = torch.zeros_like(acoustic_autoreg_sum)\n",
    "    for i in range(start_depth, 32):\n",
    "        layer = mimi_model.quantizer.acoustic_residual_vector_quantizer.layers[i - 1]\n",
    "        quantized = layer.decode(codes[:, i, :])\n",
    "        acoustic_predicted_residual = acoustic_predicted_residual + quantized\n",
    "\n",
    "    # it's just a sum\n",
    "    assert torch.allclose(acoustic_predicted_residual + acoustic_autoreg_sum, acoustic_sum)\n",
    "\n",
    "    # Demonstrate inference: reverse the process\n",
    "    all_indices = []\n",
    "    # supposing we had the full (predicted) sum\n",
    "    fake_residual = acoustic_sum - acoustic_autoreg_sum\n",
    "    for i in range(start_depth, 32):\n",
    "        layer = mimi_model.quantizer.acoustic_residual_vector_quantizer.layers[i - 1]\n",
    "        indices = layer.encode(fake_residual)\n",
    "        quantized = layer.decode(indices)\n",
    "        fake_residual = fake_residual - quantized\n",
    "        all_indices.append(indices)\n",
    "    out_indices = torch.stack(all_indices, dim=1)\n",
    "    print(codes[:, start_depth:, 2])\n",
    "    print(out_indices[:, :, 2])\n",
    "\n",
    "\n",
    "get_residual(ds['train'][0]['codes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize to CSM format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we prepare the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def tokenize_row(row: dict):\n",
    "    text_tokens, text_masks = prompt_encoder._tokenize_text_segment(\n",
    "        row[\"text_normalized\"], 0\n",
    "    )\n",
    "    audio_tokens, audio_masks = prompt_encoder._tokenize_audio(row['codes'])\n",
    "\n",
    "    return {\n",
    "        \"ground_truth\": torch.cat([text_tokens, audio_tokens], dim=0), \n",
    "        \"ground_truth_masks\": torch.cat([text_masks, audio_masks], dim=0),\n",
    "    }\n",
    "\n",
    "# TODO speed this up and/or move it to the collate fn: for libritts it doesn't really matter\n",
    "# ds = ds.map(get_targets, remove_columns=orig_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (9/9 shards): 100%|██████████| 149658/149658 [00:05<00:00, 26543.10 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4837/4837 [00:00<00:00, 27806.20 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 5736/5736 [00:00<00:00, 29566.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "orig_colnames = ds['train'].column_names\n",
    "ds = ds.map(tokenize_row, num_proc=12, remove_columns=orig_colnames)\n",
    "ds.save_to_disk(\"../datasets/tokenized_libritts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 33])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row = ds['train'][0]['ground_truth']\n",
    "example_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>[0][The moon] I gazed with a kind of wonder.<|end_of_text|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_encoder._text_tokenizer.decode(example_row[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,   1049,\n",
       "           1102,   1686,   1258,   1258,   1689,   1528,   1987,    978,    312,\n",
       "           2039,    753,    969,    598,   1084,   1268,    621,   1757,    560,\n",
       "           1734,   1527,   1117,    622,    628,    510,    623,    623,    918,\n",
       "            689,    997,   1069,   1941,    294,    774,    518,   1987,    769,\n",
       "              0],\n",
       "        [128000,     58,     15,   1483,    791,  18266,     60,    358,    342,\n",
       "          28109,    449,    264,   3169,    315,   5895,     13, 128001,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([example_row[:, 0], example_row[:, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, 1049, 1102, 1686, 1258, 1258, 1689, 1528, 1987,\n",
       "         978,  312, 2039,  753,  969,  598, 1084, 1268,  621, 1757,  560, 1734,\n",
       "        1527, 1117,  622,  628,  510,  623,  623,  918,  689,  997, 1069, 1941,\n",
       "         294,  774,  518, 1987,  769,    0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = ds['train'][0]\n",
    "audio_positions = row['ground_truth_masks'][1:, :-1].all(dim=1)\n",
    "labels = row['ground_truth'][1:, :-1]\n",
    "labels[~audio_positions] = -100\n",
    "labels[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_range = torch.arange(0, 32 * 2051, 2051)\n",
    "official_range = 2051 * torch.arange(32)\n",
    "assert torch.allclose(my_range, official_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing collation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from moshi.models import loaders\n",
    "\n",
    "ds_dev = ds['dev'].map(tokenize_row, num_proc=12, remove_columns=ds['dev'].column_names)\n",
    "\n",
    "mimi_weight = hf_hub_download(loaders.DEFAULT_REPO, loaders.MIMI_NAME)\n",
    "mimi = loaders.get_mimi(mimi_weight, device=\"cpu\")\n",
    "\n",
    "quantizer = mimi.quantizer.acoustic_quantizer.vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_dev[:32]\n",
    "\n",
    "B = len(batch[\"ground_truth\"])\n",
    "CODEBOOK_SIZE=32\n",
    "\n",
    "height = CODEBOOK_SIZE + 1\n",
    "max_input_len = max(item.shape[0] - 1 for item in batch[\"ground_truth\"])\n",
    "\n",
    "B = len(batch[\"ground_truth\"])\n",
    "tokens = torch.full((B, max_input_len, height), 0, dtype=torch.long)  # 2=some <PAD>\n",
    "targets = torch.full((B, max_input_len, 256), 0, dtype=torch.float32)\n",
    "\n",
    "pad_mask = torch.ones(B, max_input_len)\n",
    "\n",
    "for i in range(B):\n",
    "    ground_truth = batch[\"ground_truth\"][i]\n",
    "    ground_truth_masks = batch[\"ground_truth_masks\"][i]\n",
    "\n",
    "    seq_len = ground_truth.shape[0] - 1\n",
    "    tokens[i, :seq_len, :] = ground_truth[:-1, :].clone()\n",
    "\n",
    "    label = ground_truth[1:, :]\n",
    "    # full block of zeros for audio codes\n",
    "    codes = label[:, 1:-1].T\n",
    "    final_residuals = quantizer.decode(codes.unsqueeze(-1)).squeeze(-1)\n",
    "    # zero text positions with the mask\n",
    "    mask = ground_truth_masks[1:, :-1].all(dim=1)\n",
    "    final_residuals[~mask] = 0\n",
    "    targets[i, :seq_len, :] = final_residuals.unsqueeze(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
